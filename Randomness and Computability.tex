\documentclass{article}
\usepackage{amsmath,amsthm,amssymb,amsfonts, fancyhdr, color, comment, graphicx, environ, lastpage, csquotes}
\usepackage{indentfirst}
\usepackage{hyperref}
\usepackage{parskip}
\usepackage{listings}


\newcommand{\bb}{\mathbb}
\title{Topics in Randomness}
\author{Karthik Ravishankar}

\begin{document}
	\maketitle
	\tableofcontents
	\newpage
	\section{Lecture 1}
	The main notions are Kolmogorav complexity and Martin Lof Randomness.\\
	\textbf{Kolmogorov complexity}: This measures the information content or complexity of a finite binary string. $C(\sigma)$ is the legnth of the shortest binary description of $\sigma$. \\
	\textbf{Martin Lof Randomness}: An infinite binary sequence $X \in 2^\omega$ is random if it is in no effective measure zero set (typical sequences are random).\\
	\\
	How are these notions related? The idea is that random sequences should have incompressible initial segments.This is seen by the fact that For almost all $X \in 2^\omega$, $\exists c \exists^\infty n$ such that $C(X|_n) \geq n-c$ and this implies $X$ is $ML-random$. (Miller 2005, NST 2006) An $X$ as above $\iff$ $X$ is $ML-random$ relative to $0'$ - $(2 random)$.\\
	Levin(73) and Chaitin(75) used modified forms of Kolmogrov complexity to characterize randomness. Let $K: 2^{<\omega} \to \omega$ be prefix - free complexity, then by (Schnorr 75) : $X$ is ML-random $\iff$ $\exists c \forall n K(X|_n) \geq n-c$.\\
	Schnorr(71) characterized ML-randomness in terms of certain (semi computable) betting games to formalize the fact that Random reals are 'unpredictable'.\\
	Partial Randomness/Hausdorff dimension : Lutz(2000/2003) effectivized Hausdorff dimension. Now the effective Hausdorff dimension of a singleton need not be $0$. Mayordomo (2002) shoed that $dim(X) = liminf_n K(X|_n)/n = liminf_n C(X|n)/n$. So $ML - random \implies dim(X) =1$. In Lutz and Lutz 2018, they gave the point to set principle: $dim_H(E) = min_{Z \in 2^\omega} sup_{X\in E} dim^Z(X) $ for any $E \subset 2^\omega$. This has applications to geometric measure theory (Lutz, Lutz, Don Stall...).\\ \newpage
	\section{Lecture 2}
	\textbf{References:} i) Computability and Randomness - Nies 2009\\
	ii) Algorithmic Randomness and Complexity - Downey and Hirschfeldt 2010\\
	\subsection{Kolmogorov Complexity}
	\textbf{Definition:} Let $M: 2^{<\omega} \to 2^{< \omega}$ be any partial function. Then $C_M(\sigma) = min\{ |\tau :  M(\tau)=\sigma \}$ or $\infty$.
	\\
	Let $\{M_k\}_{k\in \omega}$ be an effective listing of all partial computable functions $2^{<\omega} \to 2^{< \omega}$. \\
	Then we define a partial computable $V: 2^{<\omega} \to 2^{< \omega}$ by $V(0^k1 \sigma) = M_k(\sigma)$. This is our universal machine and compresses as well as any other machine (upto a constant).\\
	\textbf{Definition:} $C(\sigma) = C_V(\sigma)$ for $V$ as above. This is called the Kolmogorov complexity of $\sigma$.
	\\
	If $M: 2^{<\omega} \to 2^{<\omega}$ is any partial computable function, then $C(\sigma) \leq^+ C_M(\sigma)$ i.e. there is at most a constant blow up in complexity and this constant is independent of $\sigma$. If $\hat{V}$ is another universal machine then $C(\sigma) =^+ C_{\hat{V}}(\sigma)$. We also have $C(\sigma) \leq^+ |\sigma|$ as the identity function is partial computable.\\
	If $h$ is partial computable, then $C(h(\sigma)) \leq^+ C(\sigma)$. We always have incompressible strings :$\forall n \exists \sigma \in 2^n$ such that $C(\sigma) \geq n$. \\
	$C(n) =^+ C(0^n) \leq^+ log_2(n+1)$. Here we are identifying $\sigma \in 2^{< \omega}$ with the natural number $n \in \omega$ if $1\sigma$ is the binary expansion of $n+1$.\\
	$C$ is not computable but there is a computable function approximating it from above (and so $0'$ computable).\\
	\\
	\textbf{Intuition}: We want random sequences to be incompressible. But no sequence $X \in 2^\omega$ has the property that $C(X|_n)\geq^+ n$ as we see below.\\
	\textbf{Lemma}: If $|\tau| = \sigma$ i.e $\sigma$ is the string representing the number $|\tau|$ then $C(\sigma \tau) \leq^+ |\tau|$, here $|\tau|$ is a number..\\
	Proof: Let $M$ be the machine which takes in $\tau$ and outputs $\sigma \tau$ where $\sigma = | \tau|$. Then $C(\sigma \tau) \leq^+ C_M(\sigma \tau) = |\tau|$.
	\\
	\textbf{Theorem:} If $X \in 2^\omega$ then $\exists^\infty n C(X|_n) \leq^+ n - log(n)$.\\
	Proof: For $k \in \omega$, let $\sigma = X|_k$ and $n = k + \sigma$ (where we are treating $\sigma$ as the number it codes) and $\sigma \tau = X|_n$. This means that $|\tau| = n-k = \sigma$. So $C(\sigma \tau) \leq^+ |\tau|$.\\
	Now $k = log(\sigma)$ (treating $\sigma$ as a number) and so $k =^+ log(n)$ and so we're done.\\
	\\
	Another consequence is as follows:\\
	\textbf{Theorem}: It is not always the case that $C(\sigma \tau) \leq^+ C(\sigma) + C(\tau)$.\\
	Proof: Fix $k \in \omega$. Take a string $\mu$ such that $|\mu| \geq 2^{k+1} +k$ ($\mu$ is long enough) and $C(\mu) \geq |\mu|$. Let $\sigma = \mu|_{k+\mu|_k}$ and let $\tau$ be the rest of $\mu$ i.e. $\sigma \tau = \mu$.\\
	Then $C(\sigma) \leq^+ |\sigma| - k$ (as in the previous theorem), and so $C(\sigma) + C(\tau) \leq^+ |\sigma| = k + |\tau| = |\mu|  - k \leq C(\mu)-k = C(\sigma \tau) - k$.\\
	\\
	The problem in all this is that we are using the length of an input to code extra bits of information. In other words program length can underestimate 'information content'.
	\section{Lecture 3}
	Last time we saw that for any sequence in $2^\omega$ there are infinitely many initial segments which are compressible by upto a factor of $log(n)$.\\
	Possible fixes to this: i) We could require monotonicity: Restrict to $M$ such that $\sigma \prec \tau \implies M(\sigma) \prec M(\tau)$ if both halt. But this isn't a very useful direction to pursue. Levin defined a monotone complexity using a more permissive model.\\
	ii) We will restrict to machines $M$ which have prefix free domains, that is $\sigma, \tau \in dom(M) \implies \sigma \not \prec \tau$. We say $M, dom(M)$ are prefix -free.\\
	Chaitin thought in terms of self delimiting Turing machines where $M(\tau) = \sigma$ if the machine has read exactly $\tau$ off the input tape before halting with output $\sigma$. This is clearly prefix free (by uniqueness of the run), and it is easy to see that any prefix - free $M$ can be given by a self delimiting machine- the machine starts doing all possible computations and checks whether it agrees with $\tau$.\\
	Intuition behind prefix free machines: Length of the program (input) is intrinsic to the program and doesn't provide extra information.\\
	We can effectively list the prefix free partial computable functions. Using this effective listing, we can define a universal machine as before: $U(0^k 1 \sigma) = M_k(\sigma)$. Note that this is prefix free- If two strings are comparable, they must be input to the same prefix free machine and so cannot be comparable!\\
	\textbf{Definition:} The prefix-free complexity of $\sigma$ denoted by $K(\sigma) = C_U(\sigma)= min \{|\tau| : U(\tau) = \sigma\}$.\\
	We have $K(\sigma) \leq^+ |\sigma| + K(|\sigma|)$.\\
	Proof: Define $M$ to be $M(\eta \sigma) = \sigma$ if $n = |\sigma|$ and $U(\eta)= n$. This is prefix free and shows $K(\sigma) \leq^+ K_M(\sigma) = |\sigma| + K(|\sigma|)$.\\
	We can give a weaker bound of $K(\sigma) \leq^+ 2 |\sigma|$ (To get rid of the $K$ in on the right hand side) above. To get this bound, just repeat digits and use $01$ as a delimitter.\\
	We can get $K(\sigma) \leq^+ |\sigma| + log|\sigma| + 2log log|\sigma|...$\\
	Now we finally have subadditivity:\\
	$K(\sigma \tau) \leq^+ K(\sigma) + K(\tau)$.\\
	Proof: Define $M$ to be $M(\tau_0\tau_1) = U(\tau_0) U(\tau_1)$ if both converge. We are using prefix free ness of $U$ here to make this well defined\\
	$K$ is not computable but is approximable from above. $0'$ computes $K$.\\
	\textbf{(Krafts Inequality)}: If $D \subset 2^{<\omega}$ is prefix-free, then $\sum_{\sigma \in D} 2^{-|\sigma|} \leq 1$.\\
	Let $[D] = \cup_{\sigma \in D} [\sigma]$. Since $D$ is prefix free $\sigma,\tau \in D$ with $\sigma \neq \tau \implies [\sigma] \cap [\tau]  = \emptyset$. Therefore $\mu([D]) = \mu(\cup [\sigma]) = \sum_\sigma \mu[\sigma] = \sum_{\sigma \in D} 2^{-|\sigma|}$ and we know $\mu[D] \leq 1$.\\
	As a corollary we get $\sum_{\sigma \in 2^{< \omega}} 2^{-K(\sigma)} \leq 1$.
	\section{Lecture 4}
	\textbf{Definition:} $X\in 2^\omega$ is $1-$ random if $K(X|_n) \geq^+ n$.\\
	In fact we later show that $lim \; K(X|_n) - n \to \infty$ when $X$ is $1-$ random.\\
	\textbf{Proposition:} Almost all $X \in 2^\omega$ are $1-$ random.\\
	Proof: Let $S_c = \{\sigma \in 2^{<\omega}: K(\sigma) \leq |\sigma| -c\}$ and $U_c = [S_c] = \{X \in 2^\omega: \exists n K(X|_n)\leq n-c\}$. Note that $X$ is not $1-$random $\iff X \in \cap_{c\in\omega} U_c$.\\
	But $\mu(U_c) = \mu([S_c]) \leq \sum_{\sigma \in S_c} \mu([\sigma]) = \sum_{\sigma \in S_c} 2^{-|\sigma|} \leq \sum_{\sigma\in S_c} 2^{-K(\sigma)-c} \leq 2^{-c} \sum_{\sigma \in 2^{<\omega} } 2^{-K(\sigma)}\leq 2^{-c}.$. Hence $\mu(\cap U_c) = 0$.\\
	\\
	Recall: If $S \subset 2^{<\omega}$ is a $c.e.$ set then $[S]$ is a $\Sigma^0_1$ class and $2^\omega - [S]$ is a $\Pi^0_1$ class.\\
	\textbf{Definition}: A Martin Lof test is an effective sequence of $\Sigma^0_1$ classes (effective open sets) $\{V_n\}_{n\in \omega}$ such that $\mu(V_n) \leq 2^{-n}$. We say $X \in 2^\omega$ passes $\{V_n\}_n$ if $X \not \in \cap V_n$. \\$X \in 2^\omega$ is Martin Lof random if it passes all $ML-$ tests.\\
	$ML-$ random $\implies 1- $ random. Every $ML-$ test gives us a measure $0, G_\delta$  set of non $ML-$ randoms. There are only countably many $ML-$ tests. Almost every $X \in 2^\omega$ is $ML-$ random.\\
	\textbf{Aside}: Every measure $0$ set $E \subset 2^\omega$ is covered by open sets of arbitrarily small measure. So $E \subset \cap_{n\in \omega} V_n$ for a Martin - Lof test $\{V_n\}$ relative to some oracle $Z$ (which basically codes the strings generating each $V_n$.)\\
	$E \subset 2^\omega$ has non zero outer measure $\iff \forall Z$ there is a $Z-ML$ random $X \in E$.\\
	Getting back to Prefix free complexity, the Kraft inequality has an effective converse.\\
	\textbf{Theorem:} Let $\{d_i\}_{i \in \omega}$ be a sequence of natural numbers such that $\sum_{i \in \omega} 2^{-d_i} \leq 1$. Then there is a prefix free sequence $\{\sigma_i\}_{i \in \omega}$ such that $|\sigma_i| = d_i$. We can compute $\sigma_i$ from $d_0,...,d_i$.\\
	Proof: At stage $n$ we have determined $\sigma_0,...,\sigma_{n-1}$. Let the terminating binary expansion of $1-\sum_{i<n} 2^{-d_i} = x_0.x_1x_2...x_m$. Inductively we will have strings with $|\tau_j| = j$ for each $x_j \neq 0$ such that $\{\sigma_i\}_{i<n}\cup \{\tau_j\}_{x_j \neq 0}$ is prefix free. \\
	Now if $x_{d_n} \neq 0$ let $\sigma_n = \tau_{d_n}$. Otherwise let $k < d_n$ be greatest such that $x_k \neq 0$. Such a $k$ will always exist by the weight condition. Then let $\sigma_n = \tau_k \frown 0^{k-d_n}$, and we add $\tau_k1, \tau_k01,...,\tau_k0^{k-d_n-1}1$ for the next stage.\\
	\textbf{Corollary (Kraft Chaitin/Machine existence theorem)} Given an effective list of requests $<d_i,\tau_i>$ with $\sum 2^{-d_i} \leq 1$ then there is a prefix free machine $M$ such that $\forall i \exists \sigma_i $ such that $|\sigma_i| = d_i$ and $M(\sigma_i)=\tau_i$.\\
	$K(\tau_i) \leq^+ d_i$. If we only have $\sum 2^{-d_i} < \infty$ then $K(\tau_i) \leq^+ d_i$. Such sets of requests are called bounded request sets.
	\newpage
	\section{Lecture 5}
	\textbf{Theorem:} $X$ is $1-$ random $\iff$ $x$ is $ML-$ random.\\
	Proof: The backward direction is done- we constructed a  $ML$ test above which prevents compressibility of initial segments.\\
	For the forward direction, assume that $X$ is not $ML$ random. There is an $ML$ test $\{V_n\}_{n\in \omega}$ such that $X \in \cap V_n$. Let $\{S_n\}$ be an effective list of $c.e.$ sets of strings such that $[S_n] = V_n$. WLOG we may assume that $S_n$ is prefix free (Just don't put a prefix, instead put a subset of the prefix which covers the same set as the prefix would). We define the request set $W = \{<|\sigma|-n, \sigma> : \sigma \in S_{2n}\}$. Then this is a bounded request set:\\ 
	$\sum_{<d,\sigma> \in W} 2^{-d} \leq \sum_{n\in \omega} \sum_{\sigma \in S_{2n}} 2^{-|\sigma|+n} = \sum_{n\in \omega} 2^n \sum_{\sigma \in S_{2n}} 2^{-|\sigma|} = \sum_n 2^n\mu(V_{2n}) \leq \sum_n 2^n 2^{-2n} < \infty$
		So $\sigma \in S_{2n} \implies K(\sigma)\leq^+ |\sigma| - n$. But $\forall n \exists k$ we have $X|_k \in S_{2n}$. So $X$ is not $1-$ random.\\
		\textbf{Corollary:} There is a universal $ML-$ test, that is a test $\{U_n\}_n$ such that $\cap_n U_n$ is eactly the non $ML-$ randoms. \\
		\textbf{Corollary:} i) The set of $ML-$ randoms is $\Sigma^0_2$.\\
		ii) $2^\omega - U_1$ is a nonempty $\Pi^0_1$ class containing only $ML-$ randoms.\\
		iii) There is a (super) low $ML-$ random.\\
		iv) The leftmost point in $2^\omega - U_1$ is left - c.e ML -random. (computably approximable from below).\\
		\\
		\textbf{Definition:} If $M$ is a prefix free machine taking binary strings to binary strings, then $\Omega_M = \mu([dom(M)]) = \sum_{\sigma \in dom(M)} 2^{-|\sigma|}$ is the halting probability of $M$.\\
		Chaitin's $\Omega$ is $\Omega = \Omega_U$.\\
		\textbf{Theorem:} $\Omega$ is a left c.e. $ML$ random.\\
		Proof: Let $U_t$ be the stage $t$ approximation to $U$. Assume $U_t $ contains strings of length at most $t$. Let $\Omega_t = \mu([dom U_t])$. Then $\{\Omega_t\}$ is a non decreasing computable sequence of rationals such that $\Omega = lim \Omega_t$.
		\\ Define a partial computable $g: 2^{<\omega} \to 2^{< \omega}$ as follows: On input $x$ of length $n$ wait for $t$ such that $0.x \leq \Omega_t \leq 0.x + 2^{-n}$. Then output the least element $y$ not in the range of $U_t$.\\
		If $X = \Omega|_n$ then such a $t$ exists. By stage $t$ all $U-$ programs of length $\leq n$ have halted. So $K(y) > n$ where $y = g(\Omega|_n)$.\\
		Therefore $K(\Sigma|_n) \geq^+ K(g(\Omega|_n))> n$.\\
		Other left c.e. $ML-$ randoms: $\sum_n 2^{-K(n)}$, $\mu(U_1)$. In general $\mu(V)$ where $V$ is a $\Sigma^0_1$ class and $2^\omega - V$ is non empty and contains noly $ML$-randoms.\\
		\textbf{Theorem:} $K$ is the least (w.r.t $\leq^+$) function $D: 2^{<\omega} \to 2^{<\omega}$ computable from above and having $\sum 2^{-D(\sigma)} < \infty$.\\
		Proof: $W = \{<D(\sigma)+k,\sigma> : \sigma \in 2^{<\omega}, k \in \omega\}$ is a bounded request set: $\sum_{<d,\sigma> \in W} 2^{-d} = \sum_{k\in \omega} \sum_{\sigma \in 2^{<\omega} }2^{-D(\sigma)-k}= \sum_{k\in \omega} 2^{-k} \sum_{\sigma \in 2^{<\omega}} 2^{-D(\sigma)} = 2 \sum_{\sigma \in 2^{<\omega}} 2^{-D(\sigma)}$. Therefore $K(\sigma) \leq^+ D(\sigma)$.
	\newpage
	\section{Lecture 6}
	For any prefix free machine $M$ let $P_M(\sigma) = \mu[M^{-1}(\sigma)]$.\\
	\textbf{Coding Theorem:} For any prefix free machine $M$, $P_M(\sigma) \leq^* 2^{-K(\sigma)}$.\\
	$P_U(\sigma) =^* 2^{-K(\sigma)}$ where $U$ is the universal machine and $\leq^*$ is '$\leq$ upto multiplicative constant'. \\
	\textbf{Corollary}: $\exists c \forall \sigma$, $\sigma$ has at most $c$ shortest $U-$ descriptions.\\
	Proof: Let $D(\sigma) = ciel(-log P_M(\sigma))$. Note that $D$ is computable approximable from above and $D(\sigma) \geq -log P_M(\sigma) \leq D(\sigma)-1$. So $2^{-D(\sigma)} \leq P_M(\sigma) \leq 2^{-D(\sigma)+1}$.
	So $\sum_\sigma $ of LHS $\leq \sum_\sigma P_M(\sigma) \leq 1$. Thus $2^{-K(\sigma)} \geq^* 2^{-D(\sigma)} \geq^* P_M(\sigma)$.\\
	Since $P_U(\sigma) \geq 2^{-K(\sigma)}$ the second statement follows.\\
	\textbf{Counting Theorem:} There is a $c\in \omega$ such that:\\
	i) $\forall d,n, |\{ \sigma \in 2^n : K(\sigma) \leq n+K(n) -d\}| < 2^c 2^{n-d}$.\\
	ii) $\forall b,n, |\{ \sigma \in 2^n : K(\sigma) \leq K(n) +b\}| < 2^c 2^{b}$.\\
	\\
	Remark: a) Most strings have complexity close$^+$ to the upper bound\\
b) $A \in 2^\omega$ is $K-$ trivial if $K(A|_n) \leq^+ K(n)$.\\ Solovay showed that $K-$ trivial $\not \implies $ computable. But computable $\implies K-$ trivial..$C-$ trivial $\implies$ computable. By $ii)$ above, at most $2^c 2^b$ $ K-$ trivials with constant $b$. So only countable many $K-$ trivials. In fact all are $\Delta^0_2$. ($0'$ computes it since $K \leq_T 0'$ and we have a $0'$ computable tree with only isolated paths - since tree is bounded width).\\
c)The counting theorem is not tight.\\
\\
Proof (Counting Theorem): Let $M$ be the prefix free machine $M(\tau) = |U(\tau)|$.
By the coding theorem $\exists c, \forall n P_M(n) <2^c 2^{-K(n)}$. Let $S_{n,d} = S = \{\sigma \in 2^n: K(\sigma) \leq |\sigma| + K(|\sigma|) - d\}$. We have $P_M(n) \geq |S| 2^{-n-K(n)+d}$. So $|S| 2^{-n-K(n)+d} < 2^c 2^{-K(n)}$ so $|S| < 2^c 2^{n-d}$.\\
\\
\textbf{Definition (Martingales)} : Let $B(\sigma)$ be the capital remaining after betting on $|\sigma|$ bits and seeing $\sigma$. $B(\sigma) =\frac{ B(\sigma0)+ B(\sigma1)}{2}$.
\newpage
	\section{Lecture 7}
 Betting on a binary string bit by bit. Start with $B(\lambda)$ 'dollars'. After betting along $\sigma$ we have $B(\sigma)$. If we bet $\gamma$ on $0$, then $B(\sigma0) = B(\sigma 1) = B(\sigma)+ \lambda + B(\sigma) - \lambda = 2 B(\sigma)$.\\
 	\textbf{Definition(Martingales)}  $B: 2^{<\omega} \to \mathbb{R}^{\geq 0}$ is a martingale if \\$\forall \sigma , B(\sigma) = \frac{B(\sigma0) + B(\sigma 1)}{2}$
	\\ B succeeds on $X \in 2^\omega$ if $lim sup B(X|_n) = \infty$. 
	Requiring $lim inf B(X|_n)$ gives the same notion although rate of convergence may change.\\
	Example: $B_\tau(\sigma)$ bets $2^{|\sigma|} $ when $\sigma \prec \tau$ and $2^{|\tau|}$ if $\tau \prec \sigma$ and $0$ otherwise. This martingale fails for all $X\in 2^\omega$. \\
	\textbf{Definition} : A supermartingale is a generalization of a martingale where we replace the equality by the inequality $S(\sigma 0 ) + S(\sigma 1) \leq 2S(\sigma)$.\\
	\textbf{Proposition} For each supermatingale $S$ there is a martingale $B$ with the same start capital, such that $\forall \sigma B(\sigma) \geq S(\sigma)$.\\
	Proof: Send extra capital to the left.\\
	\textbf{Proposition}: A weighted sum of (super)martingales is a (super) martingale as long as the start capital is finite.\\
	\textbf{(Kolmogrov's Inequality)}: If $S$ is a supermartingale and $W\subset 2^{<\omega}$ is prefix free, then $\sum_{\sigma \in W} 2^{-|\sigma|} S(\sigma) \leq S(\lambda)$.\\
	Proof: WLOG assume $W$ is finite. We prove by induction on the length $n$ of the longest string in $W$. Clearn for $n=0$, let $W_0 = \{\sigma: 0\sigma \in W\}$ and $W_1 = \{\sigma: 1\sigma \in W\}$. Then $S(\lambda) \geq 1/2 (S(0) + S(1)) \geq 1/2(\sum_{\sigma \in W_0} 2^{-|\sigma| }S(0\sigma)+ \sum_{\sigma \in W_1} 2^{-|\sigma| }S(1\sigma) ) = \sum_{\sigma \in W} 2^{-|\sigma|} S(\sigma).$\\
	\textbf{Definition}: A supermartingale $S$ is (left) c.e. if $S(\sigma)$ is left c.e. (a limit of a computable non decreasing sequence of rationals) uniformly in $\sigma$. (also called c.e. or lower semicomputable).
	\\
	\textbf{Corollary}: For a supermartingale $S$, $\mu\{Z \in 2^\omega: \exists n S(Z|_n) \geq b\} \leq S(\lambda)/b$.\\
	Proof: Let $W$ be  the prefix free set of minimal strings $\sigma$ such that $S(\sigma) \geq b$, then $\mu(W) = \sum_{\sigma \in W} 2^{-|\sigma|}$. By Kolmogrov $\sum_{\sigma \in W} 2^{-|\sigma|}  b \leq \sum_{\sigma \in W} 2^{-|\sigma|} S(\sigma) \leq S(\lambda)$.\\
	\textbf{Proposition:} The follow are equivalent for $A \in 2^\omega$.\\
	i) No c.e. supermartingale succeeds on $A$\\
	ii) No c.e. martingale succeeds on $A$\\
	iii) $\sum 2^{n-K(A|_n)}< \infty$\\
	iv) $lim K(A|_n) -n = \infty$.\\
	v) $K(A|_n) \geq^+ n$\\
	vi) $A$ is $ML$ random.\\
	Proof: $vi) \implies i)$ - Given a supermartingale $S$ with $S(\lambda) \leq 1$, define $V_n = \{Z\in 2^\omega: \exists mS(Z|_m) > 2^n\}$. Then $\{V_n\}_{n\in \omega}$ is a $ML$ test. IF $S$ succeeds on $A$, then $A \in \cap V_n$.\\
	$ii) \implies iii)$ - Define $M(\sigma) = \sum_{\tau \prec \neq \sigma} 2^{|\tau| - K(\tau) } + \sum_{\sigma \prec \tau} 2^{|\sigma| - K(\tau)} = \sum_{\tau \in \sigma} 2^{-K(\tau)} B_\tau(\sigma)$. $M(\lambda) = \sum 2^{-K(\tau)} \leq 1$. By $ii$ $M$ does not succeed on $A$. So there is a $b$ such that $M(A|_m) < b$ for all $m$, but $\sum_0^m 2^{n-K(A|_n) }\leq M(A|_m)<b \forall m$.
	\section{Lecture 8}
    As a corollary to the proof we get a universal $c.e.$ martingale which succeeds on all sequences that some $c.e.$ martingale succeeds on i.e. on all  non $ML$ randoms.\\
    \\
    Note: i)Recall that we used $M(\sigma) = \sum_{\tau \in 2^{<\omega}} 2^{-K(\tau)}
     B_\tau (\sigma)$. $f(\sigma) = 2^{-K(\sigma)}$ is maximal with respect to $\geq^*$ among functions approximable from below with $\sum f(n) < \infty$, so its the best way to combine $B_\tau$'s in a weighted way.\\
     ii) $A$ is $ML$ - random $\iff \sum 2^{n-K(A|_n)} < \infty$. Conversely if $\sum 2^{-f(n)} < \infty$, then there is an $ML-$ random $X \in 2^\omega$ such that $K(X|_n) \leq^+ n + f(n)$.\\
     iii) A c.e. supermartingale is optimal if it is maximal with respect to $\geq^*$ among $c.e. $ supermartingales.We can effectively list $c.e.$ supermartingales $\{S_n\}_{n\in \omega}$ with $S(\lambda) \leq 1$. Just take $S(\sigma) = \sum 2^{-n-1} S_n(\sigma)$ is an optimal $c.e. $ supermartingale. We can't effectively list the computable or $c.e.$ martingales, in fact there is no optimal c.e. martingale, nor a universal computable martingale (given a computable martingale, you can compute a sequence it doesn't win against, and no computable sequence is computably random).\\
     iv) \textbf{Def(A priori complexity)} :Let $S$ be an optimal $c.e.$ supermartingale and let $KM(\sigma) = |\sigma| - log_2 S(\sigma)$. This is approximable from above, $0\leq KM(\sigma) \leq^+ |\sigma| $ (the upper bound follows from the lower bound on $S(\sigma)$ since we can have a martingale that never bets and $S$ is an optimal martingale). We now get $X \in 2^\omega$ is $ML$ random $\iff KM(X|_n) =^+ n$. $X \in 2^\omega$ is computable $\iff$ $KM(X|_n) =^+ 0$. We also have monotonicity $KM(\sigma\frown i) \geq KM(\sigma)$ for $i\in \{0,1\}$. \\$KM(\sigma)\leq^+ K(\sigma)$ since $S(\sigma) \geq^* M(\sigma) \geq 2^{|\sigma|-K(\sigma)}$, where $M$ is our universal $c.e$ martingale. So $KM(\sigma) = |\sigma| - log_2 S(\sigma) \leq^+ |\sigma| - log_2(2^{|\sigma| - K(\sigma)}) = |\sigma| - |\sigma| + K(\sigma)$. We also get $KM(\sigma) = K(\sigma) \pm O(log|\sigma|)$. \\
     If $\tau$ is $\sigma$ backwards, obviously $K(\sigma) =^+ K(\tau)$ but we don't always have $KM(\sigma) \neq^+KM(\tau)$. (This is one advantage of $K$ over $KM$ since we want $\psi(\sigma)$ to be no more complex than $\sigma$ to compress with $\psi$ is partial computable).
     \\
     Next time we will see the following theorem:\\
     \textbf{Theorem(Kucera,Gacs)}: Every set is (wtt) reducible to a $ML$ random sequence.\\
     Recall: A wtt reduction is just a Turing reduction with a computable bound on the use.
     \newpage
     \section{Lecture 9}
     \textbf{Def}: A supermartingale $S$ strongly succeeds on $X\in 2^\omega$ if $lim S(X|_n) = \infty$. \\
     A $c.e.$ supermartingale is strongly universal if it strongly succeeds on every non $ML$ random.\\
     \textbf{Fact:} $M(\sigma) = \sum_{\tau \in 2^{<\omega}} 2^{K(\tau)} B_\tau(\sigma)$. is strongly universal.\\
     Proof: Let $X$ be non ML random. Fix $k$ and take $\tau \prec X$ such that $K(\tau)\leq |\tau| - k$. Then for any $n\geq |\tau|, M(X|_n) \geq 2^{-K(\tau)} B_\tau(X|_n) = 2^{-K(\tau)} 2^{|\tau|} \geq 2^k $. Since $k$ was arbitrary $M$ wins along $X$.\\
     \textbf{Corollary}: An optimal c.e. supermartingale is strongly universal.
     \\
     \textbf{Theorem : (Kucera, Gacs)} Every set is $(wtt)$ reducible to $ML$ random sequence.\\
     \textbf{Lemma:} Given $\delta > 1$ and $k\in \omega$ we can compute a length $l= l(\delta,k)$ such that for any supermartingale $S$ and any $\sigma$, $|\{\tau \in 2^l: S(\sigma \tau) \leq \delta S(\sigma)\}| \geq k$.\\
     Proof: Let $T = $ set of bad strings of length $l$. By Kolmogrov's inequality : $\sum_{\tau \in T} 2^{-|\tau|}S(\sigma \tau) \leq S(\tau)$. The left hand side is $\geq |T| 2^{-|\tau|}\delta S(\sigma)$. So $|T| \leq 2^l/\delta$. To find the $l$, pick $l$ such that $2^l - |T| \geq (1-1/\delta)@^l \geq k$. We get $l \geq log_2 k + log_2 \delta - log_2(\delta -1)$.\\
     Proof of theorem: Fix a strongly universal $c.e.$ supermartingale $S$ with $S(\lambda) \leq 1$. Fix a computable sequence of rationals $\{\delta_s\}_{s \in \omega}$ such that $\delta_s > 1$ and $\prod \delta_s \leq 2$.\\
     Let $l_s = l(\delta_s , 2)$ for each $s$. Fix $X$. We build a sequence $A$ that is $ML$ random and $X \leq_{wtt} A$. The use $u(t) = \sum_{s\leq t} l_s$.\\
     Say we have built $\sigma = A|u(t-1)$ and $S(\sigma) \leq \prod_{s<t} \delta_s$. There are at least $2$ strings $\tau \in 2^{l_s}$ such that $S(\sigma \tau) \leq \prod_{s\leq t} \delta_s$. Let $\tau_0$ be the left most and $\tau_1$ the rightmost. Define $A|_{\mu(t)} = \sigma \tau_i$ where $i  = X(t)$. Note, we can decode $X$ from $A$! This reduction is uniform too!\\
     Note: $A\geq_T 0' \oplus X$.\\
     \textbf{Corollary} : Every Turing degree above $0'$ contains a $ML$ random.\\
     \subsection{A little measure theory}
     \textbf{Definition}: Let $\mu$ be a measure. If $C \subset 2^\omega$ is a $\mu$ measurable and $\sigma$ is a string satisfying $\mu[\sigma] \neq 0$, let $\mu(C|\sigma) = \mu(C \cap [\sigma])/\mu([\sigma])$.\\
     \textbf{Theorem}: If $\mu(C)>0$ then $\forall \delta < 1 \exists \sigma \in 2^{<\omega}$ such that $\mu(C|\sigma)\geq \delta$ (Weak form of Lebesgue density)\\
     Proof: Let $\epsilon = (1/\delta -1)\mu(C)$. There is an open set $A \supset C$, (assuming $\mu$ is regular) such that $\mu(A) - \mu(C) \leq \epsilon$. So $\delta \mu(A) \leq \mu(C)$. Let $D$ be prefix free such that $A = [D]$. If no $\sigma \in D$ satisfies $\mu(C|\sigma) \geq \delta$, then $\mu(C) = \sum_{\sigma \in D} \mu(C \cap [\sigma]) < \delta \sum_{\sigma \in D} \mu([\sigma]) = \delta \mu(A) \leq \mu(C)$. But then $\mu(C) < \mu(C)$, a contradiction. \newpage
     \section{Lecture 10}
     We'll only use the weak form of Lebesgue density for Lebesgue measure $\mu$, but the proof works for regular measures (outer) and its true for any Borel measure.\\
     Lebesgue density says if $\mu$ is a Borel measure, for any $\mu-a.e. X\in 2^\omega$, and $C$ measurable we have: 
     $lim_{\sigma \prec X } \mu(C|\sigma) = 0 $ when $X\not \in C$ and $1$ otherwise.\\
     \\
     \textbf{Theorem:} $X$ is not computabe $\implies \mu\{A: A\geq_T X\} = 0$.
     \\ Proof: Assume $\mu(\{A: A\geq_T X\})>0$. Fix an index $e$ such that $\mu\{A: \varphi_e^A = X\} >0$. Let $C = \{A: \varphi_e^A = X\}$. Take $\sigma$ such that $\mu\{A: \varphi_e^{\sigma A} = X\} > 2/3$. To compute $X(n)$ wait for either $\mu\{A: \varphi_e^{\sigma A}(n)=0\} >1/3$ or $\mu\{A: \varphi_e^A(n) = 1\} > 1/3$ whichever happens is correct.\\
     Exercise: $i) \{X : X $ has $PA$ degree $\} = \{X: X$ computes a $0-1$ valued DNC function $\}$. (Similar to previous theorem)\\
     $ii)$ If $X$ is $ML$ random, then $f(e) = X|_e$ can only agree with $\varphi_e(e)$ finitely often, so $\mu\{X:X $ has DNC degree$\}=1$.
     \subsection{Relativizing $ML$ randomness}
     A $ML$ test relative to $A$ is an $A$ computable of $\Sigma^0_1[A]$ classes $\{V_n^A\}_{n \in \omega}$ such that $\mu(V_n^A)\leq 2^{-n}$.\\
     \textbf{Definition:} $X$ is $ML$ random relative to $A$ if $X$ passes every $A-ML$ test.
     \\
     Example: $X$ is $n-$ random if $X$ is $0^{n-1}$ random. So $1-$ random = $ML$ random.\\
     We can relativize the other characterizations, and everything works.\\
     Unsurprisingly $B\leq_T A$ and $X$ is $A-$ random $\implies X$ is $B-$ random.\\
     The construction of a universal $A-ML$ test is uniform in $A$. So there is a universal oracle $A-ML-test$ : $\{U_n^\square\}_{n \in \omega}$ for every $A \in 2^\omega$, $\{U_n^A\}_{n\in \omega}$ is a universal $A-ML-test$.\\
     Example: If $X$ is not computable and $Z$ is $X\oplus 0'$ random, then $Z\not \geq_T X$.\\
     Proof: Fix $e$. Using $X \oplus 0'$ we can find a $\sigma_n \prec X$ such that $\mu\{Z: \varphi_e^Z \succ \sigma_n\} \leq 2^{-n}$. Hence $\{Z : \varphi_e^Z =X\}$ is covered by the $X \oplus 0'$ ML test above.\\
     Fact: $X$ is $K-$ trivial ($K(X|_n) \leq^+ K(n)$) $\iff$ there is an $X$ random $Z$ such that $Z \geq_T X$. Recall all $K-$ trivials are $\Delta^0_2$.\\
     \textbf{Van Lambalgen's Theorem:} $A \oplus B$ is $1-$ random $\iff B$ is $1-$ random and $A$ is $B-$ random.
     \\
     \textbf{Corollary} If $A,B \in 2^\omega$ are both $1-$ random, then $A$ is $B$ random $\iff$ $B$ is $A-$ random. \\
     \textbf{Corollary} If $A \oplus B$ is $1-$ random then $A|_T B$. $A,B$ may not be a minimal pair but if $X \leq_T A,B$ with $A \oplus B$ $1-$ random, then $X$ is $K-$ trival. Such $X$ form a proper subclass of $K-$ trivials.\\
     Note: If $X$ is $1-$ random and $Z$ is $X-$ random, then $Z \not \geq_T X$. \\
     Proof: $X$ is $Z$ random by Van Lambalgen's.\\
     $Van Lambalgen's $ theorem has analogues: Its true for $1-$ generics. Product forcing (Set theory): $(G,H) $ is generic for $\mathbb{P} \times \bb{Q}$ over $V \iff G$ is $\bb{P}$ generic over $V$ and $H$ is $\bb{Q}$ generic over $V[G]$. Fubini's theorem can also be seen as an analogue.
     \section{Lecture 11}
     \textbf{Van Lambalgen's Theorem:} $A \oplus B $ is $1-$ random $\iff B $ is $1-$ random and $A$ is $B-$ random.\\
     Proof: For the forward direction let $\{U_n^\square\}_{n\in \omega} $be a universal oracle test. Let $W_n = \{\sigma\oplus\tau : |\sigma| = | \tau| and [\sigma] \subset U_n^\tau\}$. So $[W_n] = \{X\oplus Y : X \in U_n^Y\}$. Note that $\mu[W_n] = \int_Y \mu\{X \in 2^\omega: X \in U_n^Y\} dY = \int_Y \mu(U_n^Y) dY \leq \int_Y 2^{-n}dY = 2^{-n}$. Hence $\{[W_n]\}_n$ is a $ML$ test. \\
     So $A \oplus B \not \in \cap [W_n]$ which means for some $n$ we have $A \oplus B \not \in [W_n]$. So $A$ is $B-$ random. Similarly $B$ is $A-$ random and hence $1-$ random.
     \\
     \textbf{Lemma} If $\{V_n\}_{n\in \omega}$ is an $ML-$ test and $X$ is $1-$ random then $X \not \in V_n$ for almost all $n$.\\
     Proof: Let $V_n' = \cap_{m>n} V_m$ Then $\mu(V_n') \leq \sum_{m>n} 2^{-m} = 2^{-n}$ so $\{V_n' \}_{n\in \omega}$ is a $ML$ test. But $X \not \in V_n' \implies \forall m> n $ we have $X \not \in V_m$.\\
     For the backward direction of $Van\; Lambalgen's \;theorem$:\\
      Let $W_n = \{\tau \in 2^{<\omega}: (\forall Y \prec \tau) \mu\{X\in 2^\omega: X \oplus Y \in U_{2n}\} > 2^{-n}\}$. This set is $c.e.$ by compactness. \\Also $[W_n] = \{ Y \in 2^\omega: \mu\{X \in 2^\omega: X \oplus Y \in U_{2n}\} > 2^{-n}\}$. If $\mu([W_n]) > 2^{-n}$ then $\mu(U_{2n}) \geq \int_{Y \in [W_n]} \mu\{X \in 2^\omega: X\oplus Y \in U_{2n}\}dY \geq \int_{Y \in [W_n]} 2^{-n} dY = 2^{-n} \mu([W_n]) > 2^{-2n} $, a contradiction. So $\{[W_n]\}_{n\in \omega}$  form a ML test. Since $B$ is $1-$ random, $B \not \in [W_n]$ for almost all $n$. Thus for sufficiently large $n$ we have $\{X \in 2^\omega: X\oplus B \in U_{2n}\} \leq 2^{-n}$. let $V_n^B = \{X \in 2^\omega: X\oplus B \in U_{2n}\}$, this is a $\Sigma^0_1 $ class relative to $B$. Thus $\{V_n^B\}_n$ is eventually a $B$ ML test. So $A \not \in V_n^B$ for some $n$, and so $A\oplus B \not \in U_{2n}$ for this $n$. So $A \oplus B$ is $ML$ random.\\
      \textbf{Theorem:} If $Y$ is $1-$ random, $X$ is $n-$ random and $Y\leq_T X$, then $Y$ is $n-$ random.
      \\ Proof: This is an application of Van Lambalgen's theorem. Assume $n>1$. Let $Z \equiv_T 0^{n-1}$ be a $1-$ random (Kucera Gacs). So $X$ is $n-$ random $\iff X$ is $0^{n-1}$ random $\iff X$ is $Z-$ random $\iff Z$ is $X-$ random $\implies Z$ is $Y-$ random $\iff Y$ is $Z - $ random $\iff Y $ is $n-$ random.
      \\
      Fact: If $Y$ is $1-$ random and $X$ is $Z-$ random and $Y \leq_TX$ then $Y $ is $Z$ random for any $Z$.\\
      Idea: Pull a $Z-ML$ test covering $Y$ up using the reductions to a $Z-$ ML test covering $X$.\\
      \textbf{Definition:} $X$ is low for $\Omega = \sum_{\sigma \in dom U} 2^{-|\sigma|}$ (Chaitin's $\Omega$)  if $\Omega$ is $X-$ random. 
      \\
      Note: If $X$ is $1-$ random then $X$ is low for $\Omega \iff X $ is $\Omega-$ random $\iff X$ is $0'$ random $ \iff 2-$ random.\\
      Next time we'll see that all left c.e. $1$ randoms are essentially the same. So low for $\Omega$ is well defined.
      \newpage
      \section{Lecture 12}
      \subsection{Left c.e. ML randoms}
      We have seen examples $\Omega = \mu[dom U]$ and $\sum_{\sigma \in 2^{<\omega}} 2^{-K(\sigma)}$ and if $P$ is a non empty $\Pi^0_1$ class containing only randoms, take its left most element.\\
      \textbf{Theorem} If $\alpha$ is a left c.e. $ML$ random, then $\alpha \equiv_T 0'$ (even with respect to wtt)\\
      Proof: $0'$ computes all left c.e. reals. For the other direction, $\alpha$ has c.e. $DNC$ degree so $\alpha \geq_T 0'$ by Arslanov completness criteria.\\
      Define $V_n = [\alpha_s|n]$ if $n$ enters $0'$ at stage $s$ and $\emptyset $ otherwise. So $\{V_n\}$ is a $ML$ test, hence $\exists N \forall n\geq N \alpha \not \in V_n$. But then $n \in 0' \iff n \in 0'_s$ where $\alpha_s|_n = \alpha|_n$. So $\alpha \geq_{wtt} 0'$.
       \subsection{Solavay Reducibility}
       \textbf{Def}: Let $\alpha,\beta$ be left- c.e. reals, then $\beta \leq_s \alpha$ if $\exists d \in \omega, \gamma$ left c.e. such that $2^{-d} \beta + \gamma = \alpha$.\\
       $\leq_S$ is transitive and if $\beta \leq_S \alpha$ then from $\alpha|_n$ we can uniformly approximate $\beta$ to within $2^{-n+d+1}$. Therefore $\leq_S  \implies \leq_T$ but not uniformly. $K(\beta|_n) \leq^+ K(\alpha|_n)$.\\
       \textbf{Theorem:} $\alpha$ is left c.e. and $ML$ random $\iff$ there is a universal prefix free $R$ such that $\alpha = \Omega_R = \mu[dom R] \iff \alpha $ is left c.e. and Solovay complete.\\
       \textbf{Corollary} Any two left c.e. ML randoms are Solovay equivalent and so have the same initial segment complexity and are random relative to the same oracles. Therefore low for $\Omega$ is well defined.\\
       Proof:  $\Omega_R$ is left c.e. $ML$ random follows from the same proof that $\Omega$ is. \\
       Let $\alpha$ be left c.e ML random. If $\beta$ is left c.e and $\{\alpha_s\}, \{\beta_s\}$ be left c.e. approximations to $\alpha, \beta$ and assume $\beta_s < \beta_{s+1}$ and $\beta_{-1} = 0$. Build a $ML$ test $\{F_n\}$ on $[0,1]$ as follows: If $\alpha_s \in $ closure$(F_{n,s})$ do nothing, otherwise put $(\alpha_s, \alpha_s + 2^{-n} (\beta_{s+1} - \beta_{t_s}))$ into $F_n$ where $t_s$ is the last stage at which we put something into $F_n$. Note that $\mu(F_n) \leq 2^{-n} \beta \leq 2^{-n}$. If $\alpha \not \in F_n$ then $\mu(F_n) = 2^{-n} \beta$. So $\{F_n\}$ is a ML test and so $\alpha \not \in F_n$ for some $n$. Let $\gamma = \mu([0,\alpha] - F_n) = lim_s \mu([0,\alpha_s]- F_{n,s})$ which is non decreasing since we never add anything $F_{n,s+1}$ behind $\alpha_s$. So $\gamma$ is left c.e. and $2^{-n} \beta + \gamma = \alpha$ and so $\beta \leq_S\alpha$.  
       \\
       (Lecture 13) Let $\alpha$ be Solovay complete. Choose $d\in \omega, \gamma$ left c.e. such taht $2^{-d} \Omega_U+ \gamma = \alpha$. We want $2^{-d} + \gamma \leq 1$ but we can get this. Fix $d' \geq d$ such that $2^{-d'} + \alpha \leq 1$. Then $\alpha = 2^{-d} \Omega + \gamma = 2^{-d'} \Omega + (2^{-d} - 2^{-d'})\Omega + \gamma = 2^{-d'}\Omega + \gamma'$. But now $2^{-d'} +\gamma' \leq 2^{-d'}+\alpha \leq 1$. WLOG let $d = d', \gamma = \gamma'$. Let $\{d_i\}_i$ be a computable sequence such that $\gamma = \sum 2^{-d_i}$, then $\{<d,0>, <d_i,i+1\}_i$ is a bounded request set bounded by $1$ and so there is a prefix free machine $M$ such that $\Omega_M = 2^{-d} + \gamma$, and $\exists \sigma \in 2^d$ with $M(\sigma) = 0$. Define $R$ by $R(\sigma\tau) = U(\tau)$ and $R(\tau) = M(\tau)$ otherwise.Then $R$ is universal and $\Omega_R = 2^{-d}\Omega_U + \gamma$.
       
       \textbf{Barmpalias and Lewis Pye}: If $\alpha, \beta$ are left c.e. randoms and $\{\alpha_s\}, \{\beta_s\}$ are left c.e. approximations to $\alpha, \beta$, then the limit $\alpha-\alpha_s/ \beta - \beta_s$ exists and does not depend on the choice of approximations.
       \newpage
       \section{Lecture 13}
       \textbf{Definition:} (Solovay functions) A computable $g: 2^{<\omega} \to \omega$ is a Solovay function if \\
       $i) K(\sigma) \leq^+ g(\sigma) $
       \\ $ii) \exists c,\exists^\infty \sigma$ such that $g(\sigma) \leq K(\sigma) + c$. \\
       If  $g$ is right $c.e.$ and satisfies $i,ii)$ then call $g$ a weak Solovay function.
      \textbf{Proposition} If $g: 2^{<\omega} \to \omega$ is right c.e., then $K(\sigma) \leq^+ g(\sigma) \iff \sum 2^{-g(\sigma)} < \infty$.
      \\ The backward direction is by optimality of $K$.  The forward direction is since $K$ satisfies the property that we require of $g$.
      \\
      \textbf{Proposition}: There is a Solovay function.\\
      Proof: Let $g(<\sigma,\tau,t>) = |\tau|$ if $U(\tau) = \sigma, t$ is the stage at which $U(\tau) \downarrow$ and $2|<\sigma,\tau,t>|$ (something big) otherwise.\\
      Now $\sum_{\sigma \in 2^{<\omega}}  2^{-g(\sigma)} \leq \sum_{\sigma \in 2^{<\omega}} 2^{-2|\sigma|} + \sum_{\tau \in dom U} 2^{-|\tau|} = 2+ \Omega < \infty$. So $K(\sigma) \leq^+ g(\sigma)$. Now let $\tau$ be a shortest $U$ program for $\sigma$ and $U(\tau) \downarrow$ at stage $t$. Then $g(<\sigma,\tau,t>) = |\tau| = K(\sigma) \leq^+ K(<\sigma,\tau,t>)$ for such $\tau, \sigma, t$.\\\\
      From now on we look at functions as being from $\omega \to \omega$ (instead of $2^{<\omega} \to \omega$).\\
      \textbf{Theorem} Let $f: \omega \to \omega$ be right c.e.. Then $f$ is a weak Solovay function $\iff \sum 2^{-f(n)}$ is finite and ML -random. (Note that the sum is left c.e.)
      \\
      Proof: Big proof on next page
      \\
      \textbf{Facts:} If $f$ is any (weak) Solovay function then :
      \\ $a) A $ is $K$ trivial $\iff K(A|_n) \leq^+ f(n)$.\\
      $b) A$ is ML random $\iff C(A|_n)\geq^+ n-f(n)$. \\
      \textbf{Definition:} $A$ is low for $\Omega$ if $\Omega$ is $A-$ random.\\
      $A$ is weakly low for $K$ if $\exists c \exists^\infty n $ such that $K(n) \leq K^A(n) + c$.
      \\
      \textbf{Theorem} The following are equivalent for $A\in 2^{\omega}$.\\
      i) $A$ is low for $\Omega$\\
      ii) $A$ is weakly low for $K$.\\
      Proof: $A$ is low for $\Omega \iff \Omega $ is $A-$ random $\iff \sum 2^{-K(n)} $ is $A$ random $\iff \sum 2^{-K(n)} $ is finite and $K$ is right c.e. (relative to A) $\iff K$ is a weak Solovay function relative to $A$ $\iff A$ is weakly low for $K$.\\
      \\ Aside: For $A\in 2^\omega$ $A$ is low for random ($X$ ML random $\implies $ X is $A$ random) $\iff A$ is low for $K$ ($K(\sigma) \leq^+ K^A(\sigma)$) $\iff$ $A$ is $K$ trivial. Also all such $A$ are $\Delta^0_2$).
      \newpage
      \section{Lecture 14}
      \textbf{Theorem:} let $f: \omega \to \omega$ be right c.e. Then $f$ is a weak Solovay function $\iff \sum 2^{-f(n)}$ is finite and $ML$ random.\\
      Proof: Assume $\sum 2^{-f(n)}$ is finite. \\
      For the backward direction, assume that $f$ doesn't satisfy $\exists c\exists^\infty n $ such that $f(n) \leq K(n) + c \iff \Omega_f = \sum 2^{-f(n)}$ is $ML$ random. \\
      Fix a compute approximation $\{f_s\}$ to $f$ such taht $\forall n \; f_0(n)\leq f_1(n)\geq f_2(n)...$. We define a left c.e. approximation to $\Omega_f$ as follows: $a_0 = 0$ and $a_{i+1} = a_i+ d_i$ where $\{d_i\}$ is defined as follows: To find $d_i$, search for the next pair of the form $<n,0>$ or $<n,s+1>$ where $f_s(n) - f_{s+1}(n)> 0$. In the first case $d_i = 2^{-f_0(n)}$ and in the second case $d_i = 2^{-f_{s+1}(n)} - 2^{-f_s(n)}$.\\
      We say $d_i$ occurs due to $n$ and let $b_i$ = sum of all $d_j$ due to $n$ for $j\leq i$. So $lim a_i = \Omega_f$. \\
      We define a $ML$ test $\{U_c\}_{c \in \omega}$ with the goal of covering $\Omega_f$. Say that $i$ is $c-$ matched if $d_i$ occurs due to $n$ and $2^{c+1}b_i \leq 2^{-K(n)}$. If we see that $i$ is matched at stage $s$, add an interval of length $2d_i$ to $U_c$ starting at $max(\{a_i, sup U_{c,s}\}) $.\\Note $\sum \{d_i : d_i $ occurs for $n$ and is $i$ matched $\} \leq 2^{-K(n)}/2^{c+1}$. So $\mu(U_c) = 2\sum_i \{d_i : i $ is $c- $matched $\} \le 2/2^{c+1} = 2^{-c}$.\\
      So $\{U_c\}_{c\in \omega}$ is a $ML$ test. $\Omega_f \in \cap U_c$. Since $lim_{n \to \infty} f(n) - K(n) = \infty$. Fix $c$. For $n$ large enough, all corresponding $i$ will be $c-$ matched. So there is an $i(c)$ such th at $i \geq i(c) \implies i $ is $ c $ matched. For these $i'$s add intervals to $U_c$ of length $\beta = 2(\Omega_f - a_{i(c)})$, all above $a_{i(c)}$. Since $\Omega_f - a_{i(c)} < \beta$ for $\Omega_f \not \in U_c$ then it must be in one of the gaps. But each gap has supremum $a_i$ for some $i$ and $a_i \leq \Omega_f$ and $a_i \neq \Omega_f$. So $\Omega_f$ is not in any gap and the backward direction is done.\\
     Forward direction in next lecture.\\
      \textbf{Theorem}  The following are equivalent for $A \in 2^\omega$.\\
      i) $A$ is $2$ random \\
      ii) $A $ is $1$ random and low for $\Omega$\\
      iii) $A$ is $1-$ random and weakly low for $K$.
      iv) $\exists c, \exists^\infty n$ with $K(A|_n) \geq n+K(n) -c$\\
      v) $\exists c \exists^\infty n $ such that $C(A|_n) \geq n-c$.\\ \newpage
      \section{Lecture 15}
      We shall now show that if $f: \omega \to \omega$ is right c.e then $f$ is a weak Solovay function $\implies \Omega_f = \sum 2^{-f(n)}$ is finite and $ML$ random. So we want to show that if $\alpha = \Omega_f $ is not $ML$ random then $f(n) - K(n) \to \infty$. \\
      Suppose $\alpha = \Omega_f$ is not $ML$ random. We build a bounded request set $B$ as follows: If $U(\tau) = \sigma$ wait until $|\alpha_s - \sigma| < 2^{-|\sigma|}$ where $\alpha_s = \sum_{n\leq s} 2^{-f_s(n)}$. Then for all $n\geq s,m\geq 0,$ put $<n,|\tau| - |sigma| + f(n) + 2 +m> $ into $B$ upto a total weight of $2^{-|\tau|}$.  So $B$ is a bounded request set because the total weight of $B$ is $\leq \sum_{\tau \in dom(U)} 2^{-|\tau|} \leq 1$. \\
      If $\sigma = \alpha|-k$ then $s$ exists and $|\alpha - \alpha_s| < 2^{-K+1}$ and so $\sum_{n> s} 2^{f(n) } \leq \alpha - \alpha_s < 2^{-k + 1}$. So we are trying to add at most weight $\sum_{n>s}2.2^{-|\tau| + k -f(n)-2} < 2.2^{-\tau| + k - (k+1) - 2} = 2^{-|\tau|}$.\\
      If $\sigma = \alpha|_k$ for $n>s$, we have $K(n) \leq^+ |\tau| - k + f(n)$, where the constant doesnt depend on $\tau$, since for each $c$ $\exists k$ with $K(\alpha|_k) \leq kc$ so for large $n$, $K(n) \leq^+ (k-c)-k+f(n) = f(n) - c$. So $K(n) -f(n) \to \infty$.
      \\
      \textbf{Theorem}: The folowing are equivalent for $A \in 2^\omega$.\\
      i) $A$ is $2-$ random\\
      ii)$A$ is $1$ random and low for $\Omega$\\
      iii) $A$ is $1-$ random and WLK\\
      iv) $\exists c, \exists^\infty n $ such that $K(A|_n) \geq n + K(n) - c$\\
      v) $\exists c, \exists^\infty n$ such that $C(A|_n) \geq n-c$.\\
      Proof: $i\iff ii$ is by VL theorem and $\Omega\equiv_T 0'$.\\
      $ii \iff iii$ follows by low for $\Omega \iff WLK$.\\
      $iii \iff iv$ : If $A$ is $1-$ random then $\sum 2^{n-K(A|_n)}< \infty - Ample excess$\\
      Corollary: If $A$ is $1-$ random then $K^A(n) \leq^+ K(A|_n) - n$ since $\{<K(A|_n) - n + m , n>_{m,n \in \omega} $ is a bounded request set  which is $c.e.$ relative to $A$. So $K^A(n) \leq^+ K(A|_n) - n$.\\
      Now since $A$ is WLK, $K(A|_n) \geq^+ n + K^A(n) \geq^+ n + K(n)$ for infinitely many $n$.\\
      $iv \implies v:$ We have $K(\sigma) \leq^+ C(\sigma) + K(C(\sigma))$. Also $K(n) \leq^+ K(m-n ) + K(m)$. So $K(\sigma) \leq^+ |\sigma| + K(|\sigma| ) - (|\sigma| - C(\sigma) - K(|\sigma| - C(\sigma))$. Now let $d_n = n-C(A|_n)$ and assume $d_n \to \infty$. Then $n+K(n) -K(A|_n) \geq^+ d_n-K(d_n)\geq^+ d_n - 2log(d_n)\to \infty$.\\
      $v \implies i$ $K$ maximal $ \implies C$ maximal. The reverse does not hold.
      \newpage\section{Lecture 16}
      v $\implies$ i (from previous lecture): Let $U$ be a universal prefix free oracle machine. Suppose $A$ is not $2-$ random. So $\forall c, \exists^\infty n K^{0'}(A|_n)<n-c$. \\
      Let $\sigma_c$ be a string witnessing this. Now define a plain machine $M$: On input $\gamma$ let $t = |\gamma|$, then $M$ looks for a $\sigma \prec \gamma$ such that $U_t^{0'_t}(\sigma) \downarrow$. (at most one such $\sigma$). If $\gamma = \sigma \tau$ then $M(\gamma) = U_t^{0'_t}(\sigma)\tau$. So we are using the extra bits $\tau$ to get a large enough $t$ to get the computation correct. For large enough $t$, $U_t^{0'_t}(\sigma_c) = A|_n$. So $M(\sigma_c A|_{[n,t)}) = A|t$ and $C_M(A|_t) < t-c$. \\
      \\
      \subsection{A technical result} 
      Recall: A $c.e.$ set $A\subset \omega$ is simple if it is coinfinite and $\overline{A}$ has no infinite $c.e.$ subset. Clearly simple $\implies$ not computable.\\
      \textbf{Lemma}: If $H \subset 2^\omega$ is a null $\Sigma^0_3$ class. Then there is a simple set $A $ satisfying $\forall Y \in H$ with $Y$ ML random, $A \leq_T Y$.
      \\ Proof: First let $H$ be $\Pi^0_2$. Then $H = \cap V_X$ for an effective sequence of $\Sigma^0_1$ classes. We may assume $V_{x+1} \subset V_x$ by taking intersections. Let $V_x = [D_x]$ where $D_x$ is prefix free c.e. and let $V_{x,s} = [D_{x,s}]$. Want to satisfy \\
      $R_e: |W_e| = \infty \implies W_e \cap A \neq \emptyset$. \\
      Define $C(n,s) = \mu(V_{n,s})$, called the cost function. We know $\mu(V_n) \to 0$ as $n \to \infty$.  \\
      Put $x$ into $A$ at stage $s$ for the sake of $e$ if i) $W_{e,s} \cap A_s = \emptyset$. ii) $x \in W_{e,s}$ iii) $c(x,s) < 2^{-e}$ iv) $x \geq 2e$\\
      We will meet all $R_e$ so $A$ is simple.\\
      Define $\Gamma^Y $ as follows: If $\sigma$ goes into $D_n$ at stage $s$ let $\Gamma^\sigma(n) = A_s(n)$. This fails for any $Y \in V_{x,s}$ if $x$ goes into $A$ at stage $s$. But $\mu(V_{x,s}) < 2^{-e}$.\\
      Let $U_n = \cup \{V_{x,s}: x $ goes into $A$ at stage $s$ for the sake of $e>n\}$. So $\mu(U_n) < 2^{-n}$ and $\{U_n\}_{n \in \omega}$ is a $ML$ test.\\
      If $Y \in H$ is $ML$ random, so $\Gamma^H$ will be total and $Y \not \in U_n$ for some $n$ so $\Gamma^Y =^* A $ (at most $n$ mistakes). Therefore $Y \geq_T A$.\\
      To extend this to a $\Sigma^0_3$ class $H = \cup_i \cap_x V_x^i$, take $c(x,s) = \sum_i 2^{-i}\mu(V_x^i,s) $. This works out (details left out)\\
      \textbf{Theorem} (Kucera): If $Y$ is a $\Delta^0_2$ ML random then $Y$ computes a simple set. \\
      Proof: $\{Y\} = \{X : \forall n,t \exists s>t \; Y_s|_n \prec X\}$ is null $\Pi^0_2$.\\
      \textbf{Theorem} (Friedberg Muchnik): There is a $c.e.$ set strictly $\leq_T$ between $0$ and $0'$. \\
      Proof: There is a low $ML$ random $Y$. (low basis theorem). Take $A \leq_TY$ simple using previous theorem.\\
      \newpage
      \section{Lecture 17}
      \textbf{Lemma} If $H\subset 2^\omega$ is a null $\Sigma^0_3$ class then there is a simple set $A$ such that $A \leq_TY$ for each $ML$ random $Y \in H$.
      \\
      \textbf{Proposition:} If $\Omega = \Omega_0 \oplus \Omega_1$ then $(\Omega_0, \Omega_1)$ do not form a minimal pair.
      \\
      Proof: $\{\Omega_0, \Omega_1\}$ is a null $\Pi^0_2$ class. \\
      Facts: i) $A \leq_T \Omega_0, \Omega_1$ must be $K -$ trivial (we will see this)\\
      ii) These are not all $K$ trivials (We will not see this)
      \subsection{Weak 2- randomness ('strong 1 random'- Joe)}
      \textbf{Definition:} $A \in 2^\omega$ is weak $2$ random if $A$ is not in any null $\Pi^0_2$ class.\\
      So we have $2- random \implies $ weak $2 - random \implies 1 - random$: The second implication follows from the fact that $\{U_n\}$ being an $ML$ test $\implies \cap U_n$ is a null $\Pi^0_2$ class. For the first implication given a null $\Pi^0_2$ class $\cap V_n$ with the $V_n's$ nested, then $0'$ can uniformly find indices $m_n$ such that $\mu(V_{m_n}) \leq 2^{-n}$ and so we get a $0'$ ML test.\\
      $\Omega$ is $1-$ random but not weak $2-$ random because $\{\Omega\}$ is a null $\Pi^0_2$ class.\\
      We will see that every hyper immune free $1-$ random is weak $2 - $ random but not $2-$ random.\\
      \textbf{Theorem:} $A$ is weakly $2-random \iff  A$ forms a minimal pair with $9'$ (computes no noncomputable $\Delta^0_2$ set) $\iff  A$ does not compute a simple set.\\
      Proof: If $A$ is not weakly $2- $ random then it is in some null $\Pi^0_2$ class $H$ but then there is a simple set $B \leq_T A$ by the lemma. \\
      Clearly if $A, 0'$ are a minimal pair then $A$ cannot compute a simple set.\\
      If $X$ is a non computable $\Delta^0_2$ set then $\{Z : Z \geq_TX\}$ is null. Also $\{Z : Z \geq_TX\} = \cup_e \{Z : \forall n,t \exists s\geq t \varphi_{e,s}^Z(n) = X_s(n); \} $ and so is $\Sigma^0_3$ so $A \not \geq_T X$.
      \subsection{Hyperimmune degrees}
      \textbf{Definition}: Call $f : \omega \to \omega$ an escaping function if it is not dominated (equivalently majorized) by any computable function.\\
      \textbf{Definition:} $X$ has hyperimmune degree if it computes an escaping function, otherwise it has hyperimmune free degree.\\
      \textbf{Facts:} Every nonempty $\Pi^0_1$ class contains a $HIF$ member.\\
      Every noncomputable $\Sigma^0_2$ set has hyperimmune degree.\\
      \textbf{Corollary:} If $A$ is $HIF$ and $1-$ random then $A$ is weakly $2-$ random.\\
      Proof: If $A$ is not weakly $2-$ random then $A \geq_T C$ where $C$ is simple and so $A$ computes an escaping function and so $A$ would not be $HIF$.\\
      \textbf{Theorem:} If $X$ is $2-$ random then it has hyperimmune degree.\\
      \textbf{Lemma:} Let $P$ be a $\Pi^0_1[X]$ class of positive measure, then every $X-$ random has a tail in $P$.\\
      Proof: Let $V$ be $X-$ c.e, prefix free so that $P = [V]^c$. Let $V_1 = V$, and $V_{n+1} = \{\sigma\tau : \sigma \in V_n, \tau \in V\}$. $\mu[V_n] = (\mu[V_1])^n$. So a linear subsequence of $\{[V_n]\}_n$ is an $X-$ ML test. Let $Z$ be $X-$ random and $n = \mu s Z \not \in [V_n]$. So $\exists \sigma \in V_{n-1}\; \sigma \prec Z$ let $Z = \sigma Z_0$, so $Z_0 \in P$. 
      \section{Lecture 18}
      \textbf{Corollary}: Let $C $ be a degree invariant class and $P\subset C$ a positive measure $\Pi^0_1$ class. Then every $X$ random is in $C$. \\
      \textbf{Lemma}: There is a $\Pi^0_1[0']$ class $P$ of positive measure all of whose elements compute an escaping function. (by a single $\psi$).\\
      Proof: Let $R_e: \exists n \; \psi^A(n)\downarrow > \varphi_e(n)$ for all $A\in P$. We act independently for each $R_e$.  At stage $s$ if $s$ is not currently a witness for some $R_e$ ensure that $\psi^A(s)\downarrow \forall A$.\\
      Action of the $R_e$ strategy: Let $\sigma_0, ..., \sigma_{2^{e+2}}$ list string of length $e+2$ and set $i=0$. Pick a fresh witness $n$ and define $\psi^{\sigma_j}(n)=0$ when $j\neq i$. Wait for $\varphi_e(n)\downarrow$. (measure risking strategy). Set $\psi^{\sigma_i}(n) = \varphi_e(n)+1$. Increment $i$. If $i \leq 2^{e+2}, goto \;2$. \\
      Now if $\varphi_e$ is total then $R_e$ is satisfied eventually $\forall A$, otherwise we don't care. We might wait forever on some $\sigma_i$ so $\psi^A(n)\uparrow \forall \sigma_i \prec A$. $0'$ can enumerate all strings on which some $R_e$ waits forever. Let $P= \{A: \psi^A $ is total $\}$ so $P$ is a $\Pi^0_1[0']$ class. $\psi^A$ is escaping for $A \in P$ and $\mu(P) \geq 1 - \sum 2^{-e-2} = 1/2$.
      \\
      \textbf{Theorem:} Every $2-$ random computse an escaping function i.e. has hyperimmune degree.\\
      \textbf{Corollary}: There is a weak $2-$ random that is not $2-$ random.\\
      Proof:Take any HIF $1-$ random, by HIF basis theorem.\\
      \textbf{Fact:} Every $2-$ random computse a $1- generic$.
      \subsection{Scott Sets}
      We will see an application of the above results. \\
      \textbf{Definition:} i) $B$ has $PA$ degree relative to $A$ if $B$ computes an element of every  nonempty $\Pi^0_1[A]$ class.\\
     ii) $S \subset 2^\omega$ is a Turing ideal if $A\in S, B\leq_TA \implies B \in S$ and $A,B \in S \implies A\oplus B \in S$.\\
    iii) $S \subset 2^\omega$ is a Scott set if it is a Turing ideal and $\forall A \in S \exists B \in S$ such that $B$ is $PA$ relative to $A$.
      \\ These arise in the study of models of PA. They are the $2nd $ order parts of $\omega$ models of $WKL$.\\
      Question (Friedman, McAllister): If $S$ is a Scott ideal and $A \in S$ is non computable is there a $B\in S$ such that $A|_T B$.\\
      Answer (Kucera, Slaman): Yes! Broke down by cases: $A$ is/is not $K$ trivial.\\
      Question: Can there be a maximal antichain of size $2$.\\
      Conidis:Generalized $KS$ to $\omega$ models of $WWKL$ (weak weak Konig's lemma).\\
      \textbf{$\omega$ model of $WWKL$}: Turing ideal $S$ satisfying for every $A \in S, \exists B \in S$ that is random relative to $A$ or equivalenetly $\forall A \in S$ every $\Pi^0_1[A]$ class of positive measure has an element in $S$.\\
      Note : $S$ a Scott set $\implies S$ is an $\omega-$ model of $WWKL$.
      \newpage
      \section{Lecture 19}
      $S$ is a Scott set $\implies  S$ is an $\omega$ model of $WWKL$.\\
      \textbf{Theorem(Westrick)}: If $S$ is an $\omega-$ model of $WWKL$ then for every $A \in S$ there is a $B \in S$ that is either weak $2-$ random relative to $A$ or $1-$ generic relative to $A$.\\
      Proof: Let $B\in S$ be $1-$ random relative to $A$. If $B$ is not weak $2-$ random relative to $A$ then there is an $A-c.e.$ set $C \leq_T B \oplus A$ such that $C \not \leq_T A$.\\
      Fact: Every non computable $c.e.$ set computes a $1-$ generic.\\
      Relativizing if $C \not \leq_TA$ is $A-$ c.e. then there is $D \leq_TC \oplus A$ that is $1-$ generic relative to $A$. Note that $ D \in S$. \\
      Facts: Assume $A$ is not computable. i) If $B$ is $1-$ generic relative to $A$ then $B |_T A$ (In fact they form a minimal pair)\\
      ii) If $B$ is weak 2 - random relative to $A$ then $B |_T A$: 
      Clearly $B$ $A-$ random $\implies B \not \leq_T A$. for the other direction note that $\{z: z \geq_TA\} = \cup_e \{z : \varphi_e^Z = A\} = \cup_e \{z : \forall n \exists s \; \varphi_{e,s}^z(n) \downarrow = A(n)\}$ is a $\Sigma^0_3[A]$ class and so $B \not \geq_T A$.\\
      \textbf{Corollary (Westrick)}: If $S$ is an $\omega-$ model of $WWKL$ and $A_1,...,A_n \in S$ are noncomputable then there is a $B\in S$ such that $B |_T A_i \forall i$.\\
      Proof: Let $X$ be a $1-$ generic or weak $2$ random relative to $A_1 \oplus ...\oplus A_n$ hence relative to each, hence $T$ incomparable from each. 
      \subsection{Lowness and K - triviality}
      The following are equivalent for $A \in 2^\omega$:\\
       i) $A$ is low for $K$ - $K^A(\sigma) \geq^+ K(\sigma)$.\\ ii) $A$ is low for random - $X 1- $ random $\implies X \; A$ random. \\
      iii) $A$ is a base for $1-$ randomness- There is an $A-$ random $X \geq_TA$ \\
      iv) $A$ is $K-$ trivial: $K(A|_n) \leq^+ K(n)$.\\
      iv) If $Z \not \geq_T0'$ is $1-$ random then $Z \oplus A \not \geq_T 0'$.\\
      v) $A$ is computable from every low for $\Omega$ PA degree. (and a lot more)\\
      Easy Implications: $1\implies 2$: $X$ is $1-$ random $\iff K(X|_n) \geq^+ n \iff K^A(X|_n) \geq^+ n$.\\
      $2\implies 3$ By Kucera Gacs, there is a $1-$ random $X \geq_TA$ but $X$ is automatically $A - $ random.\\
      $1\implies 4$ $K(A|_n) \leq^+ K^A(A|_n) =^+ K^A(n) \leq^+ K(n)$.\\
      (hard) $2 \implies 1$: \\
      \textbf{Definition:} $A\leq_{LR} B$ if every $B-$ random is $A-$ random. $A \leq_{LK} B$ if $K^A(\sigma) \geq^+ K^B(\sigma)$.
      We want to show $A \leq_{LR} B \iff A \leq_{LK} B$. If $A \leq_{LK} B$ and $X$ is $B-$ random then $K^B(X|_n) \geq^+ n$ so $K^A(X|_n) \geq^+ K^B(X|_n) \geq^+ n$ and hence $X$ is $A-$ random.
      \\ \textbf{Lemma:} If there is a prefix free machine $M$ such that $Z = z_0 z_1 z_2 z_3...$ where $\forall i  K_M(z_i) \leq |z_i| - 1$ then $Z$ is not $ML$ random.\\
      Proof Define a prefix free macine $N$ such that on $\sigma$ it searches for a $\gamma \prec \sigma$ such that $U(\gamma) \downarrow$, if $U(\gamma)  =n $, then $N$ searches for $n \; M-$ programs $y_0,...,y_{n-1}$ such that $\sigma = \gamma y_0 ... y_{n-1}$. Then $N(\sigma) = M(y_0)...M(Y_{n-1})$. So $K(z_0...z_{n-1}) \leq^+ K_N(z_0...z_{n-1}) \leq K(n) + \sum_{i < n} K_M(z_i) \leq K(n) + |z_0...z_{n-1}| - n\leq^+ |z_0...z_{n-1}| - (n-2log n) \to \infty$ as $n \to \infty$. Hence $Z$ is not $ML-$ random.\\
      \textbf{Lemma:} If $X$ is $ML$ random and $X \in P$ where $P$ is a $\Pi^0_1$ class then $\mu(P) > 0$.
      Proof: Let $\{P_s\}_{s \in \omega}$ approximate $P$ where each $P_s$ is clopen. Let $V_n = P_{S_n} $ where $s_n = \mu s [\mu(P_s) \leq 2^{-n}]$. Then $\{V_n\}$ is a $ML$ test covering $P$.\\
      \textbf{Definition:} $X$ is weakly $1-$ random (Kurtz random) if $X$ avoids all null $\Pi^0_1$ classess weakly.\\
      Note: Weakly $1-$ generic $\implies $ weakly $1-$ random.
      
    \end{document}